hydra:
  run:
    dir: ${path:}/../config/saved_configs/env_clf_config/v_${model.version}_${now:%Y-%m-%d}_${now:%H-%M-%S}

defaults:
  - _self_
  - model: EfficientNet  # EnDNet | ResNet | ResNext | VGG | EfficientNet 
  - wandb: defaults

# dataset configuration
dataset:
  name: TAUDB
  seed: 42
  train_batch_size: 24 # high batch size will make memory error
  test_batch_size: 32
  train_dataset_path: ../dataset/real/train
  test_dataset_path: ../dataset/real/test
  subset_fraction: 1.0
  idx_exclude: 
  - 7

# optimizer configuration
optimizer:
  name: Adam # Adam | SGD
  learning_rate: 0.00001

criterion:
  name: CrossEntropyLoss # CrossEntropyLoss | BCEWithLogitsLoss
  weight_loss: False # handling with imbalance data - True | False

early_stopper:
  patience: 3
  delta: 0.1

# training configuration
training:
  device: cuda    # cpu | cuda
  num_epochs: 15
  num_classes: 6
  balance_sampler: True # handling with imbalance data - True | False with corrolation to weight_loss
                        # if True set weight_loss param to False
                        # if true dataset wont be shuffle 
                        
  debug: false
  save: true
  # save_path: ${model.name}_${model.version:if model.version is not None}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  save_path: ${model.name}/v_${model.version}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  description: null


wandb: 
  run: 
    enable: false
    name: ${training.save_path}
